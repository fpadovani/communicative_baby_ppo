# PPO Training to finetune a Baby and make it more Communicative
To run correctly the code in this repository you need this version of trl==0.8.6 (as specified in the repository). 


## Model
As baseline, we use the model pre-trained by Bastian -> [Baseline_baby](https://huggingface.co/bbunzeck/another-llama)

## PPO Datasets

Our PPO pipeline requires to have some real mother prompts to provide either to our pre-trained Baby model or to our teacher LLM model.
Therefore, I accessed the portion of dialogue data that was generated by Bastian during CHILDES data pre-processing, but not used for pretraining (`childes_dialogue2.txt`) and 
I extracted *MOT: utterances and questions that are not longer than 3 tokens (in order to have meaningful sentences). These mother prompts are stored in the `mother_promps_1.txt` file.

Since prompting the LLM at every training iteration was really computationally heavy, I asked the LLM to generate 10 possible good answers before conducting the training and stored the result in 
`./txt_files/10_answers_2.json`. I also extracted only one answer (not based on any re-ranking, but just selecting the first occurrence) and saved the result in `./txt_files/first_best_options.json`. 

To do so I used the script `answers_generation_vllm_fast.py` with the following prompt:
<pre><code>
"You are a young child having a conversation with your mother. "
"When your mother says something, you should answer as a typical kind and natural-sounding child. "
"Do NOT repeat her words. Instead, give a new, relevant answer that shows understanding. "
"Keep it short and child-like."
</code></pre>

This is the prompt I used to the Llama-3.2-3B 
